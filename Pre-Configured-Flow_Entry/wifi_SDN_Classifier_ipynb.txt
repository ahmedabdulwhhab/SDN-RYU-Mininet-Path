!pip install numpy
!pip install pandas
!pip install matplotlib
!pip install seaborn
!pip install sklearn
import numpy as np
import pandas as pd
from scipy import stats
import pickle

import numpy as np
import pandas as pd
from scipy import stats
import pickle

# Plotting libraries
import seaborn as sns
import matplotlib.pyplot as plt

# Sklearn libraries
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import label_binarize
from sklearn.model_selection import train_test_split
from sklearn.decomposition import PCA
from sklearn.linear_model import LogisticRegression
from sklearn.cluster import DBSCAN, KMeans
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Filter warnings
#warnings.filterwarnings('ignore') #filter warnings
# Show plots inline
#%matplotlib inline"



#### Loading Data\n",
#Here we load the CSV data collected from the Python script into pandas dataframe"

#mount driver google
ping_df = pd.read_csv('/content/drive/MyDrive/Machine Learning/wifi_sdn/ping_training_data.csv', delimiter='\\t')
voice_df = pd.read_csv('/content/drive/MyDrive/Machine Learning/wifi_sdn/voice_training_data.csv', delimiter='\\t')
dns_df = pd.read_csv('/content/drive/MyDrive/Machine Learning/wifi_sdn/dns_training_data.csv', delimiter='\\t')
telnet_df = pd.read_csv('/content/drive/MyDrive/Machine Learning/wifi_sdn/telnet_training_data.csv', delimiter='\\t')
df = pd.concat([ping_df, voice_df, dns_df, telnet_df], ignore_index=True)


"""
    "#### Cleaning Data\n",
    "Drop any rows that contain NaN (this happens when the training script ends abruptly)"
"""

df.dropna(inplace=True)         #Line 137
#Drop the Forward Packets, Forward Bytes, Reverse Packets, Reverse Bytes data. This data increases linearly and at a certain point in time can be any value so it is not helpful as a feature in the model.
df.drop('Forward Packets', axis=1, inplace=True)
df.drop('Forward Bytes', axis=1, inplace=True)
df.drop('Reverse Packets', axis=1, inplace=True)
df.drop('Reverse Bytes', axis=1, inplace=True)
print(df.shape)     #Line 187
df.describe()       #Line 462
df.info()
df['Traffic Type'] = df['Traffic Type'].astype('category')  #Line 514
df['Traffic Type'].cat.categories
df['Traffic Type'].cat.codes.head()     #line 577
print('Features:',df.columns[:-1].values)   #Line 611
df['Traffic Type'].value_counts()       #Line 652

#First we will split the dataset into features and targets.

X = df.drop('Traffic Type',axis=1)

y = df['Traffic Type']

X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.5, random_state=101)        #Line 705

model = LogisticRegression()        #Line 724
model.fit(X_train,y_train)          #Line 749
idx = 2590 #random number       #line 768
single_x_test = [df.iloc[idx].drop('Traffic Type').tolist()]
single_y_test = df.iloc[idx]['Traffic Type']

single_prediction = model.predict(single_x_test)        #Line 789
print('For this sample, our model predicted %s and it was actually %s' % (single_prediction[0], single_y_test))
predictions = model.predict(X_test)     #Line 808

resultsDF = pd.DataFrame({
            'true':y_test,
            'predicted':predictions
        })      #Line 898
resultsDF.head()        #Line 899
print('Accuracy: %.2f%%' % (accuracy_score(predictions,y_test)*100))    #Line 925
print(pickle.format_version)        #Line 949
pickle.dump(model,open('LogisticRegression','wb'))  #Line 958
#confusion matrix
cm = confusion_matrix(predictions,y_test, labels=y.cat.categories)
print(cm)           #Line 989

cmDF = pd.DataFrame()

for i, row in enumerate(y.cat.categories):
  temp = {}
  for j, col in enumerate(y.cat.categories):
    temp[col]=cm[i,j]
  cmDF = cmDF.append(pd.DataFrame.from_dict({row:temp},orient='index'))
print(cmDF)        #Line 1027

